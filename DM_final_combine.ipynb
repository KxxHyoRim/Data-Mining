{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DM_final_combine.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Fi8PoNA2A2Zw",
        "eIsh8w4DBSuZ",
        "QJ-UBkNVCWbZ",
        "1rbqjEtDp5y2"
      ],
      "authorship_tag": "ABX9TyNvZFC6VvkLZAdlZpT5lAX7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KxxHyoRim/Data-Mining/blob/main/DM_final_combine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Week7 Naive Bayes**\n",
        "- 나이브 베이즈 코드 출제 예정\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Naive Bayes (Iris)**"
      ],
      "metadata": {
        "id": "Fi8PoNA2A2Zw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WdzFDEZYA0Fu",
        "outputId": "87e81dd1-6607-4667-df8b-ad2ef1d8b3a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of mislabled points out of a total 75 points : 4 \n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "\n",
        "X, y = load_iris(return_X_y=True)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=0)\n",
        "gnb = GaussianNB()\n",
        "\n",
        "y_pred = gnb.fit(X_train, y_train).predict(X_test)\n",
        "print(\"Number of mislabled points out of a total %d points : %d \" %\n",
        "      (X_test.shape[0],            # test data size \n",
        "       (y_test != y_pred).sum()))  # wrong count"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 나이브 베이즈 student 데이터로 연습해봄\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_name = '/content/drive/My Drive/Data Mining/student_health_3.csv'\n",
        "\n",
        "data = pd.read_csv(file_name, encoding='cp949')\n",
        "df = pd.DataFrame(data, columns=['키', '몸무게', '학년', '수축기', '이완기'])\n",
        "\n",
        "df.head(3)\n",
        "df['학년'].unique() # 1,4학년\n",
        "\n",
        "x = df[['키', '몸무게', '수축기', '이완기']].values\n",
        "y = df['학년'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=0)\n",
        "gnb = GaussianNB()\n",
        "\n",
        "a = gnb.fit(X_train, y_train)\n",
        "y_pred = a.predict(X_test)\n",
        "\n",
        "prob = a.predict_proba(X_test)\n",
        "\n",
        "print(\"Number of mislabled points out of a total %d points : %d \" %\n",
        "      (X_test.shape[0],            # test data size \n",
        "       (y_test != y_pred).sum()))  # wrong count"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NaX9uM6o1M9u",
        "outputId": "7e280850-a24b-4acc-bbe6-2f88a1a2b02d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Number of mislabled points out of a total 563 points : 31 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Week9 Classification and Regression Trees**\n",
        "- Decision Tree\n",
        "- Random Forest"
      ],
      "metadata": {
        "id": "eIsh8w4DBSuZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Decision Tree**"
      ],
      "metadata": {
        "id": "F9zBhfL5B1-F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn import tree\n",
        "\n",
        "iris = load_iris()\n",
        "# print(iris)   #dictionary / json 형식인듯\n",
        "X, y = iris.data, iris.target\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X, y)\n",
        "\n",
        "# clf.predict(X)\n",
        "\n",
        "# tree.plot_tree(clf)"
      ],
      "metadata": {
        "id": "8HJfp186B40S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Random Forest(권장)**"
      ],
      "metadata": {
        "id": "i0RsVbCjB76x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples = 1000, n_features = 4,\n",
        "                           n_informative = 2, n_redundant = 0, \n",
        "                           random_state = 0, shuffle = False)\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=2, random_state=0)         # max_depth\n",
        "clf.fit(X, y)\n",
        "\n",
        "# RandomForestClassifier(..) 강의확인할것\n",
        "\n",
        "clf.predict([[0,0,0,0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ATDr9yjgBRBo",
        "outputId": "f0dd9395-8f93-4a3b-97d2-72853128a351"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**3. student health로 연습**\n",
        "아래 코드는 decision tree 이긴 한데, <br/>\n",
        "밑에 생성자만 바꾸면 random도 쓸 수 있음"
      ],
      "metadata": {
        "id": "nAO8Tv2SA2Ir"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = pd.read_csv(file_name, encoding='cp949')\n",
        "df = pd.DataFrame(data, columns=['키', '몸무게', '학년', '수축기', '이완기'])\n",
        "\n",
        "df.head(3)\n",
        "df['학년'].unique() # 1,4학년\n",
        "\n",
        "X = df[['키', '몸무게', '수축기', '이완기']].values\n",
        "y = df['학년'].values\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.5, random_state=0)\n",
        "\n",
        "clf = tree.DecisionTreeClassifier()\n",
        "clf = clf.fit(X_train, y_train)\n",
        "y_pred = clf.predict(X_test)\n",
        "# print(y_pred)\n",
        "# print(y_test)\n",
        "\n",
        "clf.score(X_test,y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuVQn7-g-cX3",
        "outputId": "6a28e993-e1bb-4531-9051-dc857b838bd4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9431616341030196"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Week10 Logistic Regression**\n",
        "\n",
        "**1. Logistic 코드 공부**"
      ],
      "metadata": {
        "id": "QJ-UBkNVCWbZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "X,y = load_iris(return_X_y=True)\n",
        "clf = LogisticRegression(random_state=0).fit(X, y)\n",
        "\n",
        "clf.predict(X[:2, :])\n",
        "clf.predict_proba(X[:2, :])\n",
        "clf.score(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Bz0Mqd7Cink",
        "outputId": "0581ab2e-5409-4d1a-d1a1-39b03d346916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/linear_model/_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9733333333333334"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. Linear 와의 차이점**\n",
        "\n",
        "- Logistic은 카테고리 분류에 유리\n",
        "  - Binary : Sigmoid\n",
        "  - Multi : Softmax\n",
        "\n",
        "- Linear는 선긋기를 통한 예측값 구하기 (ex. 집 값)"
      ],
      "metadata": {
        "id": "kLq0zgd9ECTU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. 과제 : student_health_3.csv에서 학년을 도출하는 Logistic Regression 구하기**\n",
        "\n",
        "predict, predict_proba 구할 때 x dataframe이랑 동일한 순서의 데이터 넣어줘야됨"
      ],
      "metadata": {
        "id": "xprC2mJeoNDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file_name = '/content/drive/My Drive/Data Mining/student_health_3.csv'\n",
        "\n",
        "df = pd.read_csv(file_name, encoding='cp949')\n",
        "df.head(3)\n",
        "df['학년'].unique() # 1,4학년\n",
        "\n",
        "x = df[['키', '몸무게', '수축기', '이완기']]\n",
        "y = df['학년']\n",
        "\n",
        "clf = LogisticRegression(random_state=0).fit(x, y)\n",
        "score = clf.score(x,y)\n",
        "predict =  clf.predict([[125.8, 27.3, 77, 58]])     # '키', '몸무게', '수축기', '이완기'\n",
        "predict_proba = clf.predict_proba([[125.8, 27.3, 77, 58]])\n",
        "\n",
        "print(\"Score : \" , score)\n",
        "print(\"Predict : \",predict)\n",
        "print(\"Predict Probability : \" , predict_proba)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FaG2phAooX5k",
        "outputId": "33be1cdc-4cb3-4dfa-bbf4-9ab1db4df622"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Score :  0.9591111111111111\n",
            "Predict :  [1]\n",
            "Predict Probability :  [[0.9643986 0.0356014]]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/base.py:446: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names\n",
            "  \"X does not have valid feature names, but\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Week11 Neural Network**\n",
        "\n",
        "**1. MLPClassifier (시험 출제 확률 높음)**"
      ],
      "metadata": {
        "id": "BdW3y1u_Ee_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_classification(n_samples=100, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, stratify=y, random_state=1)\n",
        "clf = MLPClassifier(random_state = 1, max_iter = 300).fit(X_train, y_train)\n",
        "clf.predict_proba(X_test[:5, :])\n",
        "clf.score(X_test, y_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLzYA8uIEpVh",
        "outputId": "58f8ab96-74e4-42ae-d7c4-a8e7b22b37b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.88"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**2. MLPRegressor**"
      ],
      "metadata": {
        "id": "m9cI_E4lFn3F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.datasets import make_regression\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = make_regression(n_samples=100, random_state=1)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1)\n",
        "regr = MLPRegressor(random_state = 1, max_iter = 500).fit(X_train, y_train)\n",
        "regr.predict(X_test[:2])\n",
        "round(regr.score(X_test, y_test), 3)\n",
        "\n",
        "# 회귀분석이라서 정확률은 많이 떨어짐\n",
        "\n",
        "# clf.predict_proba(X_test[:5, :])\n",
        "# 'MLPRegressor' object has no attribute 'predict_proba'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bzEDU4JkD5AH",
        "outputId": "7a967a66-38cd-497e-ccd3-ff5b011a8a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/neural_network/_multilayer_perceptron.py:696: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (500) reached and the optimization hasn't converged yet.\n",
            "  ConvergenceWarning,\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.106"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **3. 과제 (Assignment8)**\n",
        "#### **Neural Network와 기존 방법과 비교 (student_health)**\n"
      ],
      "metadata": {
        "id": "1rbqjEtDp5y2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import time\n",
        "from google.colab import drive\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\"\"\"\n",
        "1. 해당 데이터는 모두 초등학생으로 구성됨\n",
        "2. 1~6학년 까지의 데이터가 있음\n",
        "3. 수축기와, 이완기 column의 경우 1,4학년의 데이터만 있음\n",
        "\"\"\"\n",
        "\n",
        "def callKNN(X, y):\n",
        "  \n",
        "  # 데이터 분리\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
        "  # KNN Train\n",
        "  start_time = time.time()\n",
        "  kn = KNeighborsClassifier()\n",
        "  kn.fit(X_train, y_train)\n",
        "  end_time = time.time()\n",
        "  print(\"훈련 속도 : \", end_time - start_time )\n",
        "  # 점수 산정\n",
        "  print(\"KNN Score\", kn.score(X_test, y_test))\n",
        "  # Predict KNN\n",
        "  print( y_test[:5] , \"# Real Data\")\n",
        "  print(kn.predict(X_test[:5, :]),  \"# Predicted Data\\n\\n\")\n",
        "\n",
        "def callNN(X, y):\n",
        "  \n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, random_state=1)\n",
        "    \n",
        "  # MLP Classifier Train\n",
        "  start_time = time.time()\n",
        "  clf = MLPClassifier().fit(X_train, y_train)\n",
        "  end_time = time.time()\n",
        "  print(\"훈련 속도 : \", end_time - start_time )\n",
        "  # MLP 점수 산정\n",
        "  print(\"NN Score \", clf.score(X_test, y_test))\n",
        "  # Predict MLP \n",
        "  print(y_test[:5] , \"# Real Data\")\n",
        "  print(clf.predict(X_test[:5, :]), \"# Predicted Data\\n\\n\")\n",
        "\n",
        "\n",
        "\n",
        "if __name__==\"__main__\" :\n",
        "    \n",
        "  drive.mount('/content/drive')\n",
        "  csv = '/content/drive/My Drive/Data Mining/student_health_2.csv'\n",
        "\n",
        "  data = pd.read_csv(csv,  encoding='cp949')\n",
        "  df = pd.DataFrame(data, columns=['키', '몸무게', '학년', '수축기', '이완기'])\n",
        "\n",
        "  # 2개의 feature로 6개 카테고리 분류\n",
        "  X = df[['키', '몸무게']].values\n",
        "  y = df['학년'].values\n",
        "\n",
        "  callKNN(X, y)\n",
        "  callNN(X,y)\n",
        "\n",
        "\n",
        "  # 4개의 feature로 6개 카테고리 분류\n",
        "  df = df.dropna()      # 수축기와 이완기 데이터가 없는 row 제거\n",
        "  X = df[['키', '몸무게', '수축기', '이완기']].values\n",
        "  y = df['학년'].values\n",
        "\n",
        "  callKNN(X, y)\n",
        "  callNN(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tzsz6ab6p5IY",
        "outputId": "e025a88c-854a-469d-8af5-32167b7f5a4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "훈련 속도 :  0.0017070770263671875\n",
            "KNN Score 0.45352743561030234\n",
            "[3 5 6 2 2] # Real Data\n",
            "[2 6 5 3 1] # Predicted Data\n",
            "\n",
            "\n",
            "훈련 속도 :  0.3522977828979492\n",
            "NN Score  0.3169092945128779\n",
            "[3 5 6 2 2] # Real Data\n",
            "[3 3 6 3 3] # Predicted Data\n",
            "\n",
            "\n",
            "훈련 속도 :  0.0014255046844482422\n",
            "KNN Score 0.9645390070921985\n",
            "[4 4 1 4 4] # Real Data\n",
            "[4 4 1 4 4] # Predicted Data\n",
            "\n",
            "\n",
            "훈련 속도 :  0.6190905570983887\n",
            "NN Score  0.8156028368794326\n",
            "[4 4 1 4 4] # Real Data\n",
            "[1 4 1 4 1] # Predicted Data\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **4. VerySimpleCnn**"
      ],
      "metadata": {
        "id": "E460RxmCLpZP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "import numpy as np\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "x_train = x_train.reshape(60000,28,28,1)\n",
        "x_test = x_test.reshape(10000,28,28,1)\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = tensorflow.keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = tensorflow.keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=(28,28,1)))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "model.compile(loss=keras.losses.categorical_crossentropy, optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_test, y_test))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwVGpMPsLwaq",
        "outputId": "3403783b-ecda-48be-9b96-01087e49dbdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Epoch 1/12\n",
            "469/469 [==============================] - 150s 318ms/step - loss: 0.7125 - accuracy: 0.8686 - val_loss: 0.0839 - val_accuracy: 0.9746\n",
            "Epoch 2/12\n",
            "469/469 [==============================] - 143s 305ms/step - loss: 0.1536 - accuracy: 0.9554 - val_loss: 0.0539 - val_accuracy: 0.9832\n",
            "Epoch 3/12\n",
            "469/469 [==============================] - 143s 304ms/step - loss: 0.1160 - accuracy: 0.9665 - val_loss: 0.0537 - val_accuracy: 0.9834\n",
            "Epoch 4/12\n",
            "469/469 [==============================] - 143s 305ms/step - loss: 0.0937 - accuracy: 0.9726 - val_loss: 0.0442 - val_accuracy: 0.9873\n",
            "Epoch 5/12\n",
            "469/469 [==============================] - 143s 306ms/step - loss: 0.0788 - accuracy: 0.9768 - val_loss: 0.0414 - val_accuracy: 0.9886\n",
            "Epoch 6/12\n",
            "469/469 [==============================] - 143s 304ms/step - loss: 0.0749 - accuracy: 0.9775 - val_loss: 0.0451 - val_accuracy: 0.9866\n",
            "Epoch 7/12\n",
            "469/469 [==============================] - 143s 306ms/step - loss: 0.0678 - accuracy: 0.9800 - val_loss: 0.0413 - val_accuracy: 0.9883\n",
            "Epoch 8/12\n",
            "469/469 [==============================] - 143s 306ms/step - loss: 0.0592 - accuracy: 0.9818 - val_loss: 0.0467 - val_accuracy: 0.9880\n",
            "Epoch 9/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0601 - accuracy: 0.9822 - val_loss: 0.0405 - val_accuracy: 0.9885\n",
            "Epoch 10/12\n",
            "469/469 [==============================] - 142s 304ms/step - loss: 0.0545 - accuracy: 0.9832 - val_loss: 0.0385 - val_accuracy: 0.9899\n",
            "Epoch 11/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0521 - accuracy: 0.9837 - val_loss: 0.0404 - val_accuracy: 0.9893\n",
            "Epoch 12/12\n",
            "469/469 [==============================] - 142s 303ms/step - loss: 0.0459 - accuracy: 0.9860 - val_loss: 0.0416 - val_accuracy: 0.9888\n",
            "Test loss: 0.04162212461233139\n",
            "Test accuracy: 0.9887999892234802\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Week12 Discriminant Analysis**\n",
        "\n",
        "<br/>\n",
        "\n",
        "**Linear Discriminant Analysis**"
      ],
      "metadata": {
        "id": "pg94eszvKgne"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "\n",
        "X = np.array([[-1,-1], [-2, -1], [-3, -2], [1, 1], [2,1], [3,2]])\n",
        "y = np.array([1,1,1,2,2,2])\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "clf.fit(X, y)\n",
        "print(clf.predict([[-0.8, -1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ogvoxedVlILr",
        "outputId": "bfa34360-d652-4209-8667-09d0f3706579"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Quadratic Discriminant Analysis**"
      ],
      "metadata": {
        "id": "SfYUqoQAl_Oq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "X = np.array([[-1,-1], [-2, -1], [-3, -2], [1, 1], [2,1], [3,2]])\n",
        "y = np.array([1,1,1,2,2,2])\n",
        "clf = QuadraticDiscriminantAnalysis()\n",
        "clf.fit(X, y)\n",
        "print(clf.predict([[-0.8, -1]]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0-XhvfRmlnVm",
        "outputId": "b142a3c7-3018-48c2-8e90-400af1a389c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **과제 (Assignment 9)**\n",
        "\n",
        "Linear/Quadratic student_health에 저장하기"
      ],
      "metadata": {
        "id": "p9Coq6Fysx_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.model_selection import train_test_split\n",
        "from google.colab import drive\n",
        "\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#불러올 파일의 경로를 filename 변수에 저장\n",
        "file_name = '/content/drive/My Drive/Data Mining/student_health_assignment9.csv'\n",
        "\n",
        "data = pd.read_csv(file_name,  encoding='cp949')\n",
        "# print(data.shape)\n",
        "data.head(1)\n",
        "\n",
        "''' 데이터 구성 확인 '''\n",
        "grade = data['학년']\n",
        "grade.value_counts()  # 1, 4학년만 있음\n",
        "\n",
        "''' 데이터 로드 '''\n",
        "std = pd.DataFrame(data, columns=['수축기', '이완기', '키', '몸무게', '학년'])\n",
        "std = std.dropna()  # null 처리 \n",
        "std.isnull().sum()  # null 확인 \n",
        "\n",
        "X = std[['키', '몸무게', '수축기', '이완기']].values\n",
        "y = std[['학년']].values\n",
        "\n",
        "''' 데이터 분리 '''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,\n",
        "                                                    random_state=1)\n",
        "\n",
        "\n",
        "''' Linear '''\n",
        "clf = LinearDiscriminantAnalysis()\n",
        "clf.fit(X ,y)\n",
        "print(clf.predict (X_test[:5, :]))            #\n",
        "print(\"score\", clf.score(X_test, y_test))     #\n",
        "\n",
        "''' Quadratic '''\n",
        "clf = QuadraticDiscriminantAnalysis()\n",
        "clf.fit(X ,y)\n",
        "print(clf.predict (X_test[:5, :]))            #\n",
        "print(\"score\", clf.score(X_test, y_test))     #"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXI_pTl0sxan",
        "outputId": "f385436a-cb0a-4b22-f094-1ba61bb6a717"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "(282, 4)\n",
            "[4 4 1 4 4]\n",
            "score 0.9680851063829787\n",
            "[4 4 1 4 4]\n",
            "score 0.9574468085106383\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:985: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_test.shape)\n",
        "X_test[:3, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OForSBVFuQyA",
        "outputId": "959640c8-28b7-4a5f-a745-ea643f0ec983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(282, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[133.4,  36.1, 102. ,  78. ],\n",
              "       [150. ,  49.1, 125. ,  70. ],\n",
              "       [117.8,  22.8,  90. ,  60. ]])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### **과제 (Assignment 10)**\n",
        "#### **K-mean Clustering student_health_3에 적용**"
      ],
      "metadata": {
        "id": "nv--lC5RtzKu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.cluster import KMeans\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "file_name = '/content/drive/My Drive/Data Mining/student_health_3.csv'\n",
        "\n",
        "data = pd.read_csv(file_name,  encoding='cp949')\n",
        "data.head(1)\n",
        "\n",
        "grade = data['학년']\n",
        "grade.value_counts()  # 1, 4학년만 있음\n",
        "\n",
        "std = pd.DataFrame(data, columns=['수축기', '이완기', '키', '몸무게', '학년'])\n",
        "std = std.dropna()                    # null 값 처리\n",
        "\n",
        "std.loc[std['학년'] == 1, '학년'] = 1     # 1학년(저학년)을 Class1로 변경\n",
        "std.loc[std['학년'] == 4, '학년'] = 2     # 4학년(고학년)을 Class2로 변경\n",
        "\n",
        "X = std[['키', '몸무게', '수축기', '이완기']].values\n",
        "y = std[['학년']].values\n",
        "\n",
        "''' 데이터 분리 '''\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    stratify=y,     # 비율 유지 위함\n",
        "                                                    random_state=1)\n",
        "\n",
        "''' K-mean Clustring '''\n",
        "kmeans = KMeans(n_clusters=2, random_state=0).fit(X_train)\n",
        "\n",
        "\n",
        "''' Print result '''\n",
        "# 데이터 분리시 train 데이터 실제값과 예측값\n",
        "size = 10\n",
        "print(\"[Train]\")\n",
        "print(y_train[:size, 0])\n",
        "print(kmeans.labels_[:size])\n",
        "\n",
        "# 데이터 분리시 test 데이터 실제값과 예측값\n",
        "print(\"\\n[Test]\")\n",
        "print(kmeans.predict (X_test[:size, :]))\n",
        "print(y_test[:size, 0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lWLE-n3uA-F",
        "outputId": "fee07c82-768f-4391-8588-71095d29583c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "[Train]\n",
            "[2 2 2 2 1 1 1 2 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 1]\n",
            "\n",
            "[Test]\n",
            "[0 0 1 1 1 0 0 1 0 1]\n",
            "[2 2 1 2 2 2 2 2 2 1]\n"
          ]
        }
      ]
    }
  ]
}